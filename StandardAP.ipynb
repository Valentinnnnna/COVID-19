{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "# 准备工作\n",
    "# 读取数据\n",
    "df = pd.read_excel('Test_2.xlsx')\n",
    "# 插值\n",
    "df.fillna(0, inplace=True)\n",
    "data_df = df.drop('TRUE VALUE', axis=1)\n",
    "labels = df['TRUE VALUE'].copy()\n",
    "np.unique(labels)\n",
    "data = df.drop('TRUE VALUE', axis=1)\n",
    "labels = df['TRUE VALUE'].copy()\n",
    "np.unique(labels)\n",
    "# 在每一次的运行后获得的结果与这个notebook的结果相同\n",
    "np.random.seed(42)\n",
    "# 设置图片及输出\n",
    "\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "# 设置保存图片的途径\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    '''\n",
    "    只需在clustering_test_202007121.ipynb文件所在目录处，建立一个images的文件夹，运行即可保存自动图片\n",
    "    \n",
    "    :param tight_layout:\n",
    "    :param fig_id: 图片名称\n",
    "    '''\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", category=FutureWarning, module='sklearn', lineno=196)\n",
    "data.hist(bins=50, figsize=(20, 15))\n",
    "save_fig('data_describe')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# 核心功能，AP聚类\n",
    "def data_process(X, choice):\n",
    "    if choice == 0:\n",
    "        X = preprocessing.RobustScaler().fit_transform(X)\n",
    "    elif choice == 1:\n",
    "        X = preprocessing.MinMaxScaler().fit_transform(X)\n",
    "    elif choice == 2:\n",
    "        X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    elif choice == -1:\n",
    "        X = X\n",
    "    return X\n",
    "\n",
    "\n",
    "data = pd.DataFrame(data_process(np.array(data_df), 2))\n",
    "# 获取数据的数量和特征的数量\n",
    "n_samples, n_features = data.shape\n",
    "# 获取分类标签的数量\n",
    "n_labels = len(np.unique(labels))\n",
    "# 使用AP聚类算法\n",
    "af = AffinityPropagation(preference=-500, damping=0.8, random_state=0)\n",
    "print(\"聚类结果为：\", af.fit(data))\n",
    "# 获取簇的坐标\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "print(\"簇坐标为：\")\n",
    "print(cluster_centers_indices)\n",
    "# 获取分类的类别数量\n",
    "af_labels = af.labels_\n",
    "np.unique(af_labels)\n",
    "params = {'preference': [-50, -100, -150, -200], 'damping': [0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "cluster = AffinityPropagation(random_state=0)\n",
    "af_best_model = GridSearchCV(cluster, params, cv=5, scoring='adjusted_rand_score', verbose=1, n_jobs=-1)\n",
    "print(af_best_model.fit(data, labels))\n",
    "# 获取最优模型\n",
    "af1 = af_best_model.best_estimator_\n",
    "\n",
    "\n",
    "# 定义评价函数\n",
    "def get_marks(estimator, data, name=None, kmeans=None, af=None):\n",
    "    \"\"\"获取评分，有五种需要知道数据集的实际分类信息，有三种不需要，参考readme.txt\n",
    "    \n",
    "    :param estimator: 模型\n",
    "    :param name: 初始方法\n",
    "    :param data: 特征数据集\n",
    "    \"\"\"\n",
    "    estimator.fit(data)\n",
    "    print(20 * '*', name, 20 * '*')\n",
    "    if kmeans:\n",
    "        print(\"Mean Inertia Score: \", estimator.inertia_)\n",
    "    elif af:\n",
    "        cluster_centers_indices = estimator.cluster_centers_indices_\n",
    "        print(\"The estimated number of clusters: \", len(cluster_centers_indices))\n",
    "    print(\"Homogeneity Score: \", metrics.homogeneity_score(labels, estimator.labels_))\n",
    "    print(\"Completeness Score: \", metrics.completeness_score(labels, estimator.labels_))\n",
    "    print(\"V Measure Score: \", metrics.v_measure_score(labels, estimator.labels_))\n",
    "    print(\"Adjusted Rand Score: \", metrics.adjusted_rand_score(labels, estimator.labels_))\n",
    "    print(\"Adjusted Mutual Info Score: \", metrics.adjusted_mutual_info_score(labels, estimator.labels_))\n",
    "    print(\"Calinski Harabasz Score: \", metrics.calinski_harabasz_score(data, estimator.labels_))\n",
    "    print(\"Silhouette Score: \", metrics.silhouette_score(data, estimator.labels_))\n",
    "\n",
    "\n",
    "# 结果评价与输出\n",
    "get_marks(af, data=data, af=True)\n",
    "# 将AP聚类聚类的结果写入原始表格中\n",
    "df['ap_clustering_label'] = af.labels_\n",
    "# 以csv形式导出原始表格\n",
    "df.to_csv('test2_result.csv')\n",
    "# 最后两列为两种聚类算法的分类信息\n",
    "print(\"最优模型的参数：\", af_best_model.best_params_)\n",
    "# 最优模型的评分\n",
    "get_marks(af1, data=data, af=True)\n",
    "\n",
    "\n",
    "# 参数-preference,damping对结果得分可视化\n",
    "def plot_scores(preference, damping, data, labels):\n",
    "    i = []\n",
    "    y_silhouette_scores = []\n",
    "    y_calinski_harabaz_scores = []\n",
    "    preference = [round(x, 3) for x in preference]\n",
    "    damping = [round(x, 3) for x in damping]\n",
    "    for m in preference:\n",
    "        for k in damping:\n",
    "            ap_model = AffinityPropagation(preference=m, damping=k,random_state=None)\n",
    "            pred = ap_model.fit(data)\n",
    "            i.append(k)\n",
    "            if len(np.unique(pred.predict(data))) == 1:\n",
    "                y_silhouette_scores.append(-1)\n",
    "                y_calinski_harabaz_scores.append(-1)\n",
    "            else:\n",
    "                y_silhouette_scores.append(silhouette_score(data, pred.predict(data)))\n",
    "                y_calinski_harabaz_scores.append(calinski_harabasz_score(data, pred.predict(data)))\n",
    "    y_silhouette_scores = np.array(y_silhouette_scores).reshape(len(preference), len(damping))\n",
    "    y_calinski_harabaz_scores = np.array(y_calinski_harabaz_scores).reshape(len(preference), len(damping))\n",
    "    new = [y_silhouette_scores, y_calinski_harabaz_scores]\n",
    "    for j in range(len(new)):\n",
    "        plt.figure(j + 1)\n",
    "        result = pd.DataFrame(new[j])\n",
    "        result = result.rename(columns=pd.Series(damping), index=pd.Series(preference))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(15, 15))\n",
    "\n",
    "        if j == 0:\n",
    "            name = 'silhouette scores'\n",
    "            sns.heatmap(result, annot=True, vmax=1, vmin=-1, xticklabels=True, yticklabels=True, square=True,\n",
    "                        cmap=\"rainbow\")\n",
    "        elif j == 1:\n",
    "            name = 'calinski harabaz scores'\n",
    "            sns.heatmap(result, annot=True, xticklabels=True, yticklabels=True, square=True, cmap=\"rainbow\")\n",
    "        plt.ylabel('preference')\n",
    "        plt.xlabel('damping')\n",
    "        plt.title('{}_scores'.format(name))\n",
    "        save_fig('{}'.format(name))\n",
    "\n",
    "\n",
    "plot_scores(np.arange(-200, -50, 50), np.arange(0.5, 1, 0.1), data, labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
